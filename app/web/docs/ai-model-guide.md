# AI模型选择功能说明

## 功能概述

我们的聊天系统现在支持多种AI模型服务和模型选择，让您可以根据不同需求选择最适合的AI助手。

## 主要特性

### 🤖 多AI服务支持
- **OpenAI**: GPT-4, GPT-3.5 Turbo
- **Anthropic**: Claude 3 Opus, Claude 3 Sonnet  
- **Google**: Gemini Pro
- **本地模型**: Llama 2 系列

### ⚙️ 高级模型参数配置
- **创造性控制**: 调节AI回复的随机性和创造性
- **回复长度**: 控制AI回复的最大令牌数
- **实时响应**: 启用流式响应，实时显示AI生成过程

### 📊 实时状态监控
- **服务状态**: 实时显示AI服务在线状态
- **响应时间**: 监控AI服务响应性能
- **模型信息**: 显示当前使用的AI模型详情

## 使用方法

### 1. 打开模型配置
- 在聊天界面点击右上角的"模型配置"按钮
- 或在设置图标旁看到当前使用的模型状态

### 2. 选择AI服务
1. 在配置面板中选择AI服务提供商
2. 查看服务状态（在线/离线/忙碌）
3. 不同服务有不同的特色和优势

### 3. 选择AI模型
1. 根据选择的服务，系统会显示可用的AI模型
2. 每个模型都有详细的描述和特性说明
3. "最新"标签表示该模型是最新版本

### 4. 调整高级参数（可选）
1. 点击设置图标展开高级选项
2. **创造性（Temperature）**:
   - 0-0.3: 保守模式，回复更稳定一致
   - 0.4-0.8: 平衡模式，兼顾稳定性和创造性
   - 0.9-2.0: 创新模式，回复更多样化和创造性

3. **回复长度（Max Tokens）**:
   - 100-500: 简短回复
   - 500-1500: 中等长度回复
   - 1500-4096: 详细回复

4. **实时响应（Stream）**:
   - 开启: 实时显示AI生成过程
   - 关闭: 等待完整回复后显示

## 模型对比

### OpenAI模型
- **GPT-4**: 最先进的理解和推理能力，适合复杂任务
- **GPT-3.5 Turbo**: 快速响应，成本较低，适合日常对话

### Anthropic模型  
- **Claude 3 Opus**: 最强推理能力，适合分析和复杂问题
- **Claude 3 Sonnet**: 平衡性能，适合一般任务

### Google模型
- **Gemini Pro**: 多模态支持，擅长图文理解

### 本地模型
- **Llama 2 7B/13B**: 开源模型，数据隐私更好

## 使用建议

### 根据任务选择模型
- **日常对话**: GPT-3.5 Turbo, Claude Sonnet
- **复杂分析**: GPT-4, Claude Opus
- **编程辅助**: GPT-4, Gemini Pro
- **创意写作**: GPT-4 (高创造性设置)
- **隐私敏感**: 本地模型

### 参数调优建议
- **学习辅导**: 温度0.3-0.5，确保准确性
- **创意写作**: 温度0.8-1.2，增加创造性
- **代码生成**: 温度0.1-0.3，确保逻辑性
- **头脑风暴**: 温度1.0-1.5，激发创新思维

## 注意事项

1. **模型切换**: 切换模型后，新的对话将使用新模型
2. **历史对话**: 已有对话记录不会改变使用的模型
3. **网络要求**: 在线模型需要稳定的网络连接
4. **响应时间**: 不同模型的响应时间可能有差异
5. **令牌限制**: 不同模型有不同的最大令牌限制

## 故障排除

### 模型无法加载
1. 检查网络连接
2. 确认API服务状态
3. 尝试刷新页面
4. 联系技术支持

### 响应较慢
1. 检查选择的模型是否繁忙
2. 尝试切换到其他模型
3. 调整令牌数量限制
4. 关闭实时响应功能

---

通过灵活配置AI模型，您可以获得最适合当前任务的AI助手体验！